{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e34947",
   "metadata": {
    "id": "61e34947"
   },
   "source": [
    "# T5rus с промптом + LoRA + псевдотекст\n",
    "\n",
    "T5rus хорошо знает русский язык но не знает json и плохо умеет генерировать структурированные данные (он на них не учился) поэтому следующий этап - делать промежуточное преобразование в псевдокод и обратно, там мы избежим поломки структуры\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8391c3b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8391c3b5",
    "outputId": "6084508c-fdd8-4528-dd8e-45d43128de32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aHg_63hOX_7L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHg_63hOX_7L",
    "outputId": "28f06da2-3e90-4441-df8d-31c6b0f4743d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 55\n",
      "drwx------ 2 root root  4096 Apr 27 05:50 dataset\n",
      "-rw------- 1 root root 31195 Apr 29 16:44 learning_curves_T5ru.png\n",
      "drwx------ 2 root root  4096 Apr 27 05:53 library\n",
      "drwx------ 2 root root  4096 Apr 29 09:32 metrics_T5ru\n",
      "drwx------ 2 root root  4096 Apr 29 15:42 metrics_T5ru_PsC\n",
      "drwx------ 2 root root  4096 Apr 29 09:32 T5ru_lora_outputs\n",
      "drwx------ 2 root root  4096 Apr 29 15:42 T5ru_PsC_lora_outputs\n"
     ]
    }
   ],
   "source": [
    "!ls -la /content/drive/MyDrive/VKR/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "NRiT_8g7YfVZ",
   "metadata": {
    "id": "NRiT_8g7YfVZ"
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy > /dev/null 2>&1\n",
    "!python -m spacy download ru_core_news_sm > /dev/null 2>&1\n",
    "!pip install wandb > /dev/null 2>&1\n",
    "!pip install datasets > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eZxJ6K4Sn7tq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZxJ6K4Sn7tq",
    "outputId": "672e2ea1-277c-4622-8ded-9867b0350037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n",
      "3.5.1\n",
      "0.30.2\n",
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)\n",
    "print(huggingface_hub.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b149213",
   "metadata": {
    "id": "0b149213"
   },
   "source": [
    "Будем напрямую генерировать json по сцене, для этого дообучим T5(Text-To-Text Transfer Transformer) + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd09b180",
   "metadata": {
    "id": "bd09b180"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftConfig,PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# отключаем их все чтобы картинку не портили\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "#DATA_DIR = Path(\"/content/drive/MyDrive/VKR/dataset/dataset_tmp\").expanduser()\n",
    "DATA_DIR = Path(\"/content/drive/MyDrive/VKR/dataset/dataset_small\").expanduser()\n",
    "MODEL_NAME = \"sberbank-ai/ruT5-base\"\n",
    "\n",
    "lib_path = os.path.abspath(os.path.join(os.getcwd(), '/content/drive/MyDrive/VKR/'))\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "from library.metrics_pseudo import evaluate_all_metrics\n",
    "from library.safe_compute_metrics import safe_compute_metrics\n",
    "\n",
    "# перевод в псевдотекст и обратно\n",
    "from library.utils import json_to_pseudo_text, pseudo_text_to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccb28b",
   "metadata": {
    "id": "94ccb28b"
   },
   "source": [
    "### Промпт с \"few shorts\" примерами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cb877e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5cb877e",
    "outputId": "3c09abfa-0cb9-424f-c017-ee61a43c54c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "# промпт очень большой, поэтому нужно чтобы все влезало\n",
    "PROMPT = \"\"\"\n",
    "Ты должен проанализировать описание сцены и вернуть ответ в специальном псевдоформате.\n",
    "\n",
    "Твоя задача:\n",
    "- Найди все объекты, упомянутые в описании, и их признаки.\n",
    "- Верни результат строго в псевдоформате — одной строкой.\n",
    "\n",
    "Формат:\n",
    "объект1 (признак1 признак2) объект2 () объект3 (признак)\n",
    "\n",
    "Требования:\n",
    "- Каждый объект указывается один раз.\n",
    "- Признаки пишутся через пробел внутри круглых скобок.\n",
    "- Если признаки отсутствуют, используй пустые скобки ().\n",
    "- Не добавляй объектов или признаков, которых нет в описании.\n",
    "- В ответе не должно быть никаких пояснений, комментариев или заголовков — только одна строка с результатом.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "Описание: Маленький красный стол стоит у окна.\n",
    "Ответ:\n",
    "стол (маленький красный) окно ()\n",
    "\n",
    "Описание: {description}\n",
    "\n",
    "Ответ:\n",
    "\"\"\"\n",
    "\n",
    "print(len(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ac571cd",
   "metadata": {
    "id": "8ac571cd"
   },
   "outputs": [],
   "source": [
    "class CustomEvaluateCallback(TrainerCallback):\n",
    "    def __init__(self, save_path, val_dataset=None, tokenizer=None):\n",
    "        self.save_path = Path(save_path)\n",
    "        self.save_path.mkdir(exist_ok=True, parents=True)\n",
    "        self.metrics_history = []\n",
    "\n",
    "        self.val_dataset = val_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics is None:\n",
    "            return\n",
    "\n",
    "        # Логируем метрики\n",
    "        # 'f1_objects': только по объектам,\n",
    "        # 'f1_attributes_macro': Это среднее значение F1 по атрибутам (признакам),\n",
    "        #                        рассчитанное отдельно для каждого объекта,\n",
    "        #                        а потом усреднённое по всем объектам.\n",
    "        #'f1_attributes_weighted': То же, но взвешенное по числу признаков в эталоне\n",
    "        #'f1_global_obj_attr_pairs': F1 по всем (объект, признак) парам как единому множеству\n",
    "        #'f1_combined_simple': простое среднее между двух ключевых компонент качества (F1 объекты и F1 признаки)\n",
    "        #'f1_combined_weighted': взвешенное среднее двух F1-метрик с учетом числа объектов и числа признаков\n",
    "\n",
    "        metrics_to_log = {\n",
    "            \"epoch\": state.epoch,\n",
    "            \"f1_objects\": metrics.get(\"f1_objects\", 0.0),\n",
    "            \"f1_attributes_macro\": metrics.get(\"f1_attributes_macro\", 0.0),\n",
    "            \"f1_attributes_weighted\": metrics.get(\"f1_attributes_weighted\", 0.0),\n",
    "            \"f1_combined_simple\": metrics.get(\"f1_combined_simple\", 0.0),\n",
    "            \"f1_combined_weighted\": metrics.get(\"f1_combined_weighted\", 0.0),\n",
    "            \"f1_global_obj_attr_pairs\": metrics.get(\"f1_global_obj_attr_pairs\", 0.0),\n",
    "            \"valid_json_rate\": metrics.get(\"valid_json_rate\", 0.0),\n",
    "        }\n",
    "\n",
    "        print(\"metrics_to_log\", metrics_to_log)\n",
    "\n",
    "        self.metrics_history.append(metrics_to_log)\n",
    "        print(f\"\\n Custom evaluation at epoch {state.epoch:.2f}: {metrics_to_log}\")\n",
    "\n",
    "        with open(self.save_path / \"metrics_history.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.plot_metrics()\n",
    "\n",
    "        # Вывод 3-х примеров\n",
    "        if self.val_dataset and self.tokenizer:\n",
    "            model = kwargs[\"model\"]\n",
    "            model.eval()\n",
    "\n",
    "            # покажем случайные генерации\n",
    "            examples = random.sample(list(self.val_dataset), k=3)\n",
    "\n",
    "            print(\"\\nПримеры валидации:\")\n",
    "            for ex in examples:\n",
    "                input_text = ex[\"input\"]\n",
    "                label = ex[\"target\"]\n",
    "\n",
    "                inputs = self.tokenizer(\n",
    "                    input_text, return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=INPUT_SEQ_LENGTH\n",
    "                ).to(model.device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output_ids = model.generate(\n",
    "                        input_ids=inputs[\"input_ids\"],\n",
    "                        attention_mask=inputs[\"attention_mask\"],\n",
    "                        max_length=OUTPUT_SEQ_LENGTH,\n",
    "                        num_beams=NUM_BEAMS, # попробовать 2, 4, 8\n",
    "                        #temperature=TEMPERATURE,\n",
    "                        early_stopping=True\n",
    "                    )\n",
    "                pred = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "                #print(f\"\\nОписание: {input_text}\")\n",
    "                print(f\"\\nПравильный ответ:\\n{label}\")\n",
    "                print(f\"\\nПредсказание:\\n{pred}\")\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        if not self.metrics_history:\n",
    "            return\n",
    "        epochs = [m[\"epoch\"] for m in self.metrics_history]\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        for key in [\"f1_objects\",\n",
    "                    \"f1_attributes_macro\",\n",
    "                    \"f1_attributes_weighted\",\n",
    "                    \"f1_combined_simple\",\n",
    "                    \"f1_combined_weighted\",\n",
    "                    \"f1_global_obj_attr_pairs\",\n",
    "                    \"valid_json_rate\"]:\n",
    "            plt.plot(epochs, [m[key] for m in self.metrics_history], label=key)\n",
    "        plt.xlabel(\"Эпоха\")\n",
    "        plt.ylabel(\"Метрика\")\n",
    "        plt.title(\"Кривые метрик по эпохам\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(self.save_path / \"learning_curves.png\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc97beb3",
   "metadata": {
    "id": "dc97beb3"
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds_json = []\n",
    "    labels_json = []\n",
    "\n",
    "    for pred_str, label_str in zip(preds, labels):\n",
    "        try:\n",
    "            pred_json = pseudo_text_to_json(pred_str.strip())\n",
    "        except Exception as e:\n",
    "            #print(\"Ошибка парсинга предсказания:\", pred_str, \"|\", e)\n",
    "            pred_json = []\n",
    "\n",
    "        try:\n",
    "            label_json = pseudo_text_to_json(label_str.strip())\n",
    "        except Exception as e:\n",
    "            #print(\"Ошибка парсинга ground truth:\", label_str, \"|\", e)\n",
    "            label_json = []\n",
    "\n",
    "        preds_json.append(pred_json)\n",
    "        labels_json.append(label_json)\n",
    "\n",
    "    # посмотрим что выдает\n",
    "    print(preds_json[0], labels_json[0])\n",
    "\n",
    "    return preds_json, labels_json\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Если predictions — logits, нужно брать argmax\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "    # logits -> ids\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Декодируем токены\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Превращаем строки в JSON-списки через внешний postprocess_text\n",
    "    preds_json, labels_json = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    # Метрики\n",
    "    f1_objects_list = []\n",
    "    f1_attributes_macro_list = []\n",
    "    f1_attributes_weighted_list = []\n",
    "    f1_combined_simple_list = []\n",
    "    f1_combined_weighted_list = []\n",
    "    f1_global_obj_attr_pairs_list = []\n",
    "\n",
    "    valid = 0\n",
    "\n",
    "    for pred, label in zip(preds_json, labels_json):\n",
    "\n",
    "        #print(\"pred:\", pred, type(pred))\n",
    "        #print(\"label:\", label, type(label))\n",
    "        #print(\"-------------------------------\")\n",
    "\n",
    "        if not isinstance(pred, list) or not isinstance(label, list):\n",
    "            f1_objects_list.append(0.0)\n",
    "            f1_attributes_macro_list.append(0.0)\n",
    "            f1_attributes_weighted_list.append(0.0)\n",
    "            f1_combined_simple_list.append(0.0)\n",
    "            f1_combined_weighted_list.append(0.0)\n",
    "            f1_global_obj_attr_pairs_list.append(0.0)\n",
    "            #print(\"bad evaluation\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            scores = evaluate_all_metrics(label, pred)\n",
    "            print(\"good:\",scores)\n",
    "            f1_objects_list.append(scores[\"f1_objects\"])\n",
    "            f1_attributes_macro_list.append(scores[\"f1_attributes_macro\"])\n",
    "            f1_attributes_weighted_list.append(scores[\"f1_attributes_weighted\"])\n",
    "            f1_combined_simple_list.append(scores[\"f1_combined_simple\"])\n",
    "            f1_combined_weighted_list.append(scores[\"f1_combined_weighted\"])\n",
    "            f1_global_obj_attr_pairs_list.append(scores[\"f1_global_obj_attr_pairs\"])\n",
    "            valid += 1\n",
    "        except Exception as e:\n",
    "            f1_objects_list.append(0.0)\n",
    "            f1_attributes_macro_list.append(0.0)\n",
    "            f1_attributes_weighted_list.append(0.0)\n",
    "            f1_combined_simple_list.append(0.0)\n",
    "            f1_combined_weighted_list.append(0.0)\n",
    "            f1_global_obj_attr_pairs_list.append(0.0)\n",
    "            #print(\"bad scores\", e)\n",
    "    total = len(decoded_preds)\n",
    "    print(\"total:\", total)\n",
    "\n",
    "    aggregated_scores = {\n",
    "        \"f1_objects\": round(sum(f1_objects_list) / total, 4),\n",
    "        \"f1_attributes_macro\": round(sum(f1_attributes_macro_list) / total, 4),\n",
    "        \"f1_attributes_weighted\": round(sum(f1_attributes_weighted_list) / total, 4),\n",
    "        \"f1_combined_simple\": round(sum(f1_combined_simple_list) / total, 4),\n",
    "        \"f1_combined_weighted\": round(sum(f1_combined_weighted_list) / total, 4),\n",
    "        \"f1_global_obj_attr_pairs\": round(sum(f1_global_obj_attr_pairs_list) / total, 4),\n",
    "        \"valid_json_rate\": round(valid / total, 4),\n",
    "        \"total_samples\": total,\n",
    "        \"valid_samples\": valid,\n",
    "    }\n",
    "    print(\"aggregated_scores:\", aggregated_scores)\n",
    "    return aggregated_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xLtU1NHcs93q",
   "metadata": {
    "id": "xLtU1NHcs93q"
   },
   "source": [
    "### Параметры модели и обучения\n",
    "\n",
    "инъекции будем делать во все слои связанные с вниманием - это должно сделать модель гибче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "YpHNWwvts8NU",
   "metadata": {
    "id": "YpHNWwvts8NU"
   },
   "outputs": [],
   "source": [
    "lora_rank = 8\n",
    "lora_alpha = 16\n",
    "lora_target_modules=[\"q\", \"v\"]   # в какие слои делаем инъекции\n",
    "lora_dropout=0.1\n",
    "\n",
    "per_device_train_batch_size = 4\n",
    "num_train_epochs = 5\n",
    "\n",
    "INPUT_SEQ_LENGTH = 1100\n",
    "OUTPUT_SEQ_LENGTH = 512\n",
    "\n",
    "# параметры генерации\n",
    "NUM_BEAMS = 6\n",
    "\n",
    "# лучше beam подлиннее чем температура, тк у нас структурированный текст\n",
    "#TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tvsP0jk_1BTi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "tvsP0jk_1BTi",
    "outputId": "9289d043-3d14-4da6-fa28-a8927491f03c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250430_112937-d2ci5qpx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shiltsov-da/vkr-hse-object-detection/runs/d2ci5qpx' target=\"_blank\">stoic-glade-35</a></strong> to <a href='https://wandb.ai/shiltsov-da/vkr-hse-object-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shiltsov-da/vkr-hse-object-detection' target=\"_blank\">https://wandb.ai/shiltsov-da/vkr-hse-object-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shiltsov-da/vkr-hse-object-detection/runs/d2ci5qpx' target=\"_blank\">https://wandb.ai/shiltsov-da/vkr-hse-object-detection/runs/d2ci5qpx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity=\"shiltsov-da\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"vkr-hse-object-detection\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    group=\"T5LoRAtext2textPsC\",\n",
    "    tags=[\"text2text\", \"lora\", MODEL_NAME],\n",
    "    config={\n",
    "        \"architecture\": \"FlanT5-LoRA-text2text-PsC\",\n",
    "        \"notebook\":\"T5ru-LoRA-text2text-parser-v2-Colab.ipynb\",\n",
    "        \"base_model\": MODEL_NAME,\n",
    "        \"lora_rank\": lora_rank,\n",
    "        \"lora_alpha\": lora_alpha,\n",
    "        \"lora_target_modules\": lora_target_modules,\n",
    "        \"per_device_train_batch_size\": per_device_train_batch_size,\n",
    "        \"num_train_epochs\": num_train_epochs\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2SoLCDMs_3jT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SoLCDMs_3jT",
    "outputId": "a9e96a0f-e7f5-4b40-e787-d64b714fe66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '\\nТы должен проанализировать описание сцены и вернуть ответ в специальном псевдоформате.\\n\\nТвоя задача:\\n- Найди все объекты, упомянутые в описании, и их признаки.\\n- Верни результат строго в псевдоформате — одной строкой.\\n\\nФормат:\\nобъект1 (признак1 признак2) объект2 () объект3 (признак)\\n\\nТребования:\\n- Каждый объект указывается один раз.\\n- Признаки пишутся через пробел внутри круглых скобок.\\n- Если признаки отсутствуют, используй пустые скобки ().\\n- Не добавляй объектов или признаков, которых нет в описании.\\n- В ответе не должно быть никаких пояснений, комментариев или заголовков — только одна строка с результатом.\\n\\nПримеры:\\n\\nОписание: Маленький красный стол стоит у окна.\\nОтвет:\\nстол (маленький красный) окно ()\\n\\nОписание: Острая лопата стоит рядом с ведром.\\n\\nОтвет:\\n', 'target': 'лопата (острая) ведро ()'}\n"
     ]
    }
   ],
   "source": [
    "# Грузим батчи\n",
    "def make_target(scene_objects):\n",
    "    objects_dict = {}\n",
    "    for obj in scene_objects:\n",
    "        for name, attrs in obj.items():\n",
    "            objects_dict[name] = attrs\n",
    "    ps_text = json_to_pseudo_text([objects_dict])\n",
    "    return ps_text\n",
    "\n",
    "data = []\n",
    "for path in sorted(DATA_DIR.glob(\"*.jsonl\")):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            description = item[\"description\"]\n",
    "            target = make_target(item[\"scene\"][\"objects\"])\n",
    "            data.append({\n",
    "                \"input\": PROMPT.format(description=description),\n",
    "                \"target\": target,\n",
    "            })\n",
    "\n",
    "\n",
    "# Делаем датасет\n",
    "dataset = Dataset.from_list(data)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "train_ds, val_ds = dataset[\"train\"], dataset[\"test\"]\n",
    "\n",
    "print(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b895227",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "58877fa41490498d933e3b44e19c45f7",
      "f861d864aec5454b937bea74368fa287",
      "2450d93c7a9042a4830a2888dda875fc",
      "86a38d91c7884fec9307ddc12c5d2570",
      "279311b7b53c42e8b82bc1b2a8e3dee6",
      "3e32e17c33da4d9794aabd1c1717c027",
      "7b9e83c55ad246729c5be747c73ae262",
      "f6b7acf12727418d827a6cdf6b00a57b",
      "46dc82e68a674b129aafc99cf4927b9e",
      "315d315ab75a425d8d6cd9d6bac96189",
      "066e038f8a0c48ce912bed6526ed7540",
      "7e6c938a54e34543a7fd9fba27297118",
      "26186dbcbcc34a2c92b0137624b73403",
      "d677a730bb704b718f11cbb5e2314622",
      "0ffaca97765c42d6b335a53bbc2be714",
      "7aa2c1bd8edf404ead0faad35b35159f",
      "5614c6d61cf4441bbd21bfcd00d1b5ea",
      "f6115fc3752840c6b4145093a5c748e9",
      "019569ec3bdd424b9fc3dfca37f8fe0d",
      "a6272f05ce8e4d6b8ebfa2282d4cd422",
      "3f7045a08106433fb61bd4eb71f93c3f",
      "af0bf2b4858a436381f483e50ce9bf02"
     ]
    },
    "id": "3b895227",
    "outputId": "d60b48a5-2a8d-459f-c034-88e5b6f45ed8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58877fa41490498d933e3b44e19c45f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/286 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6c938a54e34543a7fd9fba27297118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3005' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3005/180 : < :, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 06:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Objects</th>\n",
       "      <th>F1 Attributes Macro</th>\n",
       "      <th>F1 Attributes Weighted</th>\n",
       "      <th>F1 Combined Simple</th>\n",
       "      <th>F1 Combined Weighted</th>\n",
       "      <th>F1 Global Obj Attr Pairs</th>\n",
       "      <th>Valid Json Rate</th>\n",
       "      <th>Total Samples</th>\n",
       "      <th>Valid Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.049969</td>\n",
       "      <td>0.583600</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.048369</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.047596</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.047917</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.380200</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'стол': ['ярая', 'толстая']}, {'лампа': ['яркая']}] [{'книга': ['толстая', 'красная']}, {'стол': ['высокий', 'прямой']}, {'лампа': ['яркая']}]\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.3333, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.5667, 'f1_combined_weighted': 0.52}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2778, 'f1_attributes_weighted': 0.5556, 'f1_global_obj_attr_pairs': 0.5, 'f1_combined_simple': 0.3889, 'f1_combined_weighted': 0.5238}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.125, 'f1_attributes_weighted': 0.1667, 'f1_global_obj_attr_pairs': 0.2222, 'f1_combined_simple': 0.3958, 'f1_combined_weighted': 0.4167}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.4444}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.5, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.5}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.4, 'f1_combined_weighted': 0.8}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.4}\n",
      "good: {'f1_objects': 0.3333, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.1667, 'f1_combined_weighted': 0.3333}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.4}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.6667, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 1.0, 'f1_combined_simple': 0.7333, 'f1_combined_weighted': 0.9}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5714, 'f1_attributes_macro': 0.2, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.2, 'f1_combined_simple': 0.3857, 'f1_combined_weighted': 0.4524}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2667}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.25, 'f1_combined_weighted': 0.25}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.4583, 'f1_combined_weighted': 0.5}\n",
      "total: 16\n",
      "aggregated_scores: {'f1_objects': 0.5836, 'f1_attributes_macro': 0.1262, 'f1_attributes_weighted': 0.2014, 'f1_combined_simple': 0.3549, 'f1_combined_weighted': 0.4442, 'f1_global_obj_attr_pairs': 0.1715, 'valid_json_rate': 1.0, 'total_samples': 16, 'valid_samples': 16}\n",
      "metrics_to_log {'epoch': 1.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      " Custom evaluation at epoch 1.00: {'epoch': 1.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      "Примеры валидации:\n",
      "\n",
      "Правильный ответ:\n",
      "ключ () телевизор (плоский черный) кровать (мягкая) шкаф (высокий)\n",
      "\n",
      "Предсказание:\n",
      "шкаф (плоский плоский) телевизор (плоский плоский) кровать ()\n",
      "\n",
      "Правильный ответ:\n",
      "книга (толстая красная) стол (высокий прямой) лампа (яркая)\n",
      "\n",
      "Предсказание:\n",
      "стол () лампа (яркая) книга (яркая)\n",
      "\n",
      "Правильный ответ:\n",
      "стул (удобный мягкий высокий) стол (высокий широкий прямой) лампа (яркая) занавес ()\n",
      "\n",
      "Предсказание:\n",
      "стул () лампа (яркая) лампа (яркая) лампа (яркая)\n",
      "[{'стол': ['ярая', 'толстая']}, {'лампа': ['яркая']}] [{'книга': ['толстая', 'красная']}, {'стол': ['высокий', 'прямой']}, {'лампа': ['яркая']}]\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.3333, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.5667, 'f1_combined_weighted': 0.52}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2778, 'f1_attributes_weighted': 0.4167, 'f1_global_obj_attr_pairs': 0.4444, 'f1_combined_simple': 0.3889, 'f1_combined_weighted': 0.4583}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.3333}\n",
      "good: {'f1_objects': 0.8571, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.4, 'f1_combined_simple': 0.5119, 'f1_combined_weighted': 0.8095}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.5, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.5}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.4, 'f1_combined_weighted': 0.8}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 0.3333, 'f1_combined_simple': 0.325, 'f1_combined_weighted': 0.6}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.2857}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.6667, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 1.0, 'f1_combined_simple': 0.7333, 'f1_combined_weighted': 0.9}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.4583, 'f1_combined_weighted': 0.7778}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.25, 'f1_combined_weighted': 0.1667}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.4583, 'f1_combined_weighted': 0.5}\n",
      "total: 16\n",
      "aggregated_scores: {'f1_objects': 0.589, 'f1_attributes_macro': 0.1476, 'f1_attributes_weighted': 0.3281, 'f1_combined_simple': 0.3683, 'f1_combined_weighted': 0.4657, 'f1_global_obj_attr_pairs': 0.2031, 'valid_json_rate': 1.0, 'total_samples': 16, 'valid_samples': 16}\n",
      "metrics_to_log {'epoch': 2.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      " Custom evaluation at epoch 2.00: {'epoch': 2.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      "Примеры валидации:\n",
      "\n",
      "Правильный ответ:\n",
      "гаечный ключ (металлический тяжёлый) домкрат (металлический) аккумулятор (тяжёлый плоский квадратный)\n",
      "\n",
      "Предсказание:\n",
      "ключ (металлический) аккумулятор (металлический) аккумулятор (металлический) аккумулятор (металлический) аккумулятор (металлический) аккумулятор (металлический)\n",
      "\n",
      "Правильный ответ:\n",
      "ключ () телевизор (плоский черный) кровать (мягкая) шкаф (высокий)\n",
      "\n",
      "Предсказание:\n",
      "телевизор (плоский плоский плоский) ключ () кровать (гладкая) кровать ()\n",
      "\n",
      "Правильный ответ:\n",
      "яблоко () хлеб (мягкий) сыр (вкусный)\n",
      "\n",
      "Предсказание:\n",
      "хлеб (мягкий) яблоко (вкусное) хлеб (вкусный) хлеб (вкусный) хлеб (вкусный) хлеб (вкусный)\n",
      "[{'стол': ['ярая', 'толстая']}, {'лампа': ['яркая']}] [{'книга': ['толстая', 'красная']}, {'стол': ['высокий', 'прямой']}, {'лампа': ['яркая']}]\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.3333, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.5667, 'f1_combined_weighted': 0.52}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2778, 'f1_attributes_weighted': 0.5556, 'f1_global_obj_attr_pairs': 0.5, 'f1_combined_simple': 0.3889, 'f1_combined_weighted': 0.5238}\n",
      "good: {'f1_objects': 1.0, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.1667, 'f1_global_obj_attr_pairs': 0.2222, 'f1_combined_simple': 0.5833, 'f1_combined_weighted': 0.5833}\n",
      "good: {'f1_objects': 0.8571, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.4, 'f1_combined_simple': 0.5119, 'f1_combined_weighted': 0.8095}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.5, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.5}\n",
      "good: {'f1_objects': 1.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.5, 'f1_combined_weighted': 1.0}\n",
      "good: {'f1_objects': 0.3333, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.1667, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.4}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.2857}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.6667, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 1.0, 'f1_combined_simple': 0.7333, 'f1_combined_weighted': 0.9}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5714, 'f1_attributes_macro': 0.2, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.2, 'f1_combined_simple': 0.3857, 'f1_combined_weighted': 0.4524}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2667}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2222, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.5, 'f1_combined_simple': 0.3611, 'f1_combined_weighted': 0.6111}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.4583, 'f1_combined_weighted': 0.5}\n",
      "total: 16\n",
      "aggregated_scores: {'f1_objects': 0.6122, 'f1_attributes_macro': 0.1531, 'f1_attributes_weighted': 0.2847, 'f1_combined_simple': 0.3827, 'f1_combined_weighted': 0.497, 'f1_global_obj_attr_pairs': 0.2277, 'valid_json_rate': 1.0, 'total_samples': 16, 'valid_samples': 16}\n",
      "metrics_to_log {'epoch': 3.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      " Custom evaluation at epoch 3.00: {'epoch': 3.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      "Примеры валидации:\n",
      "\n",
      "Правильный ответ:\n",
      "полотенце (мягкое белое) шезлонг (удобный легкий раскладной)\n",
      "\n",
      "Предсказание:\n",
      "полотенце (мягкое мягкое мягкое) полотенце (мягкое мягкое) полотенце (мягкое) полотенце (мягкое) полотенце (мягкое) полотенце () полотенце (мягкое) полотенце (мягкое) полотенце ()\n",
      "\n",
      "Правильный ответ:\n",
      "стул (удобный мягкий высокий) стол (высокий широкий прямой) лампа (яркая) занавес ()\n",
      "\n",
      "Предсказание:\n",
      "стул () лампа (яркая) лампа (яркая) лампа (яркая)\n",
      "\n",
      "Правильный ответ:\n",
      "скамейка (удобная) фонарь (яркий легкий) урна (пластиковая) качели (легкие)\n",
      "\n",
      "Предсказание:\n",
      "урна (пластиковая) фонарь (яркий) урна (пластиковая) урна (пластиковая)\n",
      "[{'стол': ['ярая', 'толстая']}, {'лампа': ['яркая']}] [{'книга': ['толстая', 'красная']}, {'стол': ['высокий', 'прямой']}, {'лампа': ['яркая']}]\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.3333, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.5667, 'f1_combined_weighted': 0.52}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2778, 'f1_attributes_weighted': 0.4167, 'f1_global_obj_attr_pairs': 0.4444, 'f1_combined_simple': 0.3889, 'f1_combined_weighted': 0.4583}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.125, 'f1_attributes_weighted': 0.1667, 'f1_global_obj_attr_pairs': 0.2222, 'f1_combined_simple': 0.3958, 'f1_combined_weighted': 0.4167}\n",
      "good: {'f1_objects': 0.8571, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.4, 'f1_combined_simple': 0.5119, 'f1_combined_weighted': 0.8095}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.5, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.5}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.4, 'f1_combined_weighted': 0.8}\n",
      "good: {'f1_objects': 0.3333, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.1667, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 0.3333, 'f1_combined_simple': 0.325, 'f1_combined_weighted': 0.6}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.2857}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.6667, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 1.0, 'f1_combined_simple': 0.7333, 'f1_combined_weighted': 0.9}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5714, 'f1_attributes_macro': 0.2, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.2, 'f1_combined_simple': 0.3857, 'f1_combined_weighted': 0.4524}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2222, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.5, 'f1_combined_simple': 0.3611, 'f1_combined_weighted': 0.6111}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.3333}\n",
      "total: 16\n",
      "aggregated_scores: {'f1_objects': 0.5789, 'f1_attributes_macro': 0.1505, 'f1_attributes_weighted': 0.3177, 'f1_combined_simple': 0.3647, 'f1_combined_weighted': 0.4679, 'f1_global_obj_attr_pairs': 0.2272, 'valid_json_rate': 1.0, 'total_samples': 16, 'valid_samples': 16}\n",
      "metrics_to_log {'epoch': 4.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      " Custom evaluation at epoch 4.00: {'epoch': 4.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      "Примеры валидации:\n",
      "\n",
      "Правильный ответ:\n",
      "дерево (зелёное) цветок (красный ароматный) скамейка (деревянная длинная тяжелая)\n",
      "\n",
      "Предсказание:\n",
      "дерево (деревянное) скамейка (деревянная) цветок (яркий) дерево (деревянное)\n",
      "\n",
      "Правильный ответ:\n",
      "станок () труба (длинная) конвейер (длинный)\n",
      "\n",
      "Предсказание:\n",
      "конвейер (длинный длинный) труба (длинная) конвейер (длинный) труба (длинная)\n",
      "\n",
      "Правильный ответ:\n",
      "барная_стойка (длинная) стул (деревянный удобный высокий) бокал ()\n",
      "\n",
      "Предсказание:\n",
      "стул (высокий) барная стойка (широкая) барная стойка (широкая)\n",
      "[{'стол': ['ярая', 'толстая']}, {'лампа': ['яркая']}] [{'книга': ['толстая', 'красная']}, {'стол': ['высокий', 'прямой']}, {'лампа': ['яркая']}]\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.3333, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.5667, 'f1_combined_weighted': 0.52}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2778, 'f1_attributes_weighted': 0.4167, 'f1_global_obj_attr_pairs': 0.4444, 'f1_combined_simple': 0.3889, 'f1_combined_weighted': 0.4583}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.125, 'f1_attributes_weighted': 0.1667, 'f1_global_obj_attr_pairs': 0.2222, 'f1_combined_simple': 0.3958, 'f1_combined_weighted': 0.4167}\n",
      "good: {'f1_objects': 0.8571, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.4, 'f1_combined_simple': 0.5119, 'f1_combined_weighted': 0.8095}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.1667, 'f1_attributes_weighted': 0.5, 'f1_global_obj_attr_pairs': 0.2857, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.5}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.4, 'f1_combined_weighted': 0.8}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.25, 'f1_combined_weighted': 0.25}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 0.3333, 'f1_combined_simple': 0.325, 'f1_combined_weighted': 0.6}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.2857}\n",
      "good: {'f1_objects': 0.8, 'f1_attributes_macro': 0.6667, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 1.0, 'f1_combined_simple': 0.7333, 'f1_combined_weighted': 0.9}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.25, 'f1_attributes_weighted': 1.0, 'f1_global_obj_attr_pairs': 0.25, 'f1_combined_simple': 0.4583, 'f1_combined_weighted': 0.7778}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.2, 'f1_combined_weighted': 0.2}\n",
      "good: {'f1_objects': 0.4, 'f1_attributes_macro': 0.125, 'f1_attributes_weighted': 0.3333, 'f1_global_obj_attr_pairs': 0.3333, 'f1_combined_simple': 0.2625, 'f1_combined_weighted': 0.36}\n",
      "good: {'f1_objects': 0.5, 'f1_attributes_macro': 0.2222, 'f1_attributes_weighted': 0.6667, 'f1_global_obj_attr_pairs': 0.5, 'f1_combined_simple': 0.3611, 'f1_combined_weighted': 0.6111}\n",
      "good: {'f1_objects': 0.6667, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'f1_combined_simple': 0.3333, 'f1_combined_weighted': 0.3333}\n",
      "total: 16\n",
      "aggregated_scores: {'f1_objects': 0.5952, 'f1_attributes_macro': 0.1615, 'f1_attributes_weighted': 0.3802, 'f1_combined_simple': 0.3783, 'f1_combined_weighted': 0.5014, 'f1_global_obj_attr_pairs': 0.2512, 'valid_json_rate': 1.0, 'total_samples': 16, 'valid_samples': 16}\n",
      "metrics_to_log {'epoch': 5.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      " Custom evaluation at epoch 5.00: {'epoch': 5.0, 'f1_objects': 0.0, 'f1_attributes_macro': 0.0, 'f1_attributes_weighted': 0.0, 'f1_combined_simple': 0.0, 'f1_combined_weighted': 0.0, 'f1_global_obj_attr_pairs': 0.0, 'valid_json_rate': 0.0}\n",
      "\n",
      "Примеры валидации:\n",
      "\n",
      "Правильный ответ:\n",
      "скамейка (удобная) фонарь (яркий легкий) урна (пластиковая) качели (легкие)\n",
      "\n",
      "Предсказание:\n",
      "урна (пластиковая) фонарь (яркий) урна (пластиковая) урна (пластиковая)\n",
      "\n",
      "Правильный ответ:\n",
      "книга (толстая красная) стол (высокий прямой) лампа (яркая)\n",
      "\n",
      "Предсказание:\n",
      "стол (высокий прямой прямой прямой прямой) лампа (яркая)\n",
      "\n",
      "Правильный ответ:\n",
      "дерево (зеленый) скамейка (удобная прочная) цветок (ароматный)\n",
      "\n",
      "Предсказание:\n",
      "дерево (деревянное) цветок (зеленый) скамейка (прочная) скамейка (прочная) цветок (зеленый)\n"
     ]
    }
   ],
   "source": [
    "# Токенайзер\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(example):\n",
    "    inputs = tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=INPUT_SEQ_LENGTH)\n",
    "    targets = tokenizer(example[\"target\"], padding=\"max_length\", truncation=True, max_length=OUTPUT_SEQ_LENGTH)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "\n",
    "    # сохраняем оригинал обратно в пример\n",
    "    # inputs[\"target_raw\"] = example[\"target_raw\"]\n",
    "    return inputs\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=False)\n",
    "val_ds = val_ds.map(preprocess, batched=False)\n",
    "\n",
    "# Грузим модель + LoRA\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=lora_rank, # ранг низкоранговой матрицы\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=lora_target_modules,\n",
    "    # target_modules=[\"q\", \"k\", \"v\", \"o\"]\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Обучение\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/VKR/T5ru_PsC_lora_outputs\",\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    logging_dir=\"/content/drive/MyDrive/VKR/logs_T5ru_PsC\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=1, # для маленькой памяти GPU\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    #report_to=\"none\",\n",
    "    report_to=\"wandb\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        CustomEvaluateCallback(\n",
    "            save_path=\"/content/drive/MyDrive/VKR/metrics_T5ru_PsC/\",\n",
    "            val_dataset=val_ds,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# грузим уже обученную\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"/content/drive/MyDrive/VKR/T5ru_PsC_lora_outputs\")\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IDPMFG6h5Q57",
   "metadata": {
    "id": "IDPMFG6h5Q57"
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilVy_yTT1D5P",
   "metadata": {
    "id": "ilVy_yTT1D5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1970de3a",
   "metadata": {
    "id": "1970de3a"
   },
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5703fb35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5703fb35",
    "outputId": "8d5eedd6-8911-4f8f-ef09-30fbd53bffed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Введите описание сцены: кот сидел под большим деревом\n",
      "кот (большой) дерево (большое) дерево (деревянное) кот (большой) дерево ()\n",
      "[{'кот': ['большой']}, {'дерево': ['большое']}, {'дерево': ['деревянное']}, {'кот': ['большой']}, {'дерево': []}]\n",
      "\n",
      "Предсказание:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"кот\": [\n",
      "      \"большой\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"дерево\": [\n",
      "      \"большое\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"дерево\": [\n",
      "      \"деревянное\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"кот\": [\n",
      "      \"большой\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"дерево\": []\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"/content/drive/MyDrive/VKR/T5ru_PsC_lora_outputs\"  # путь к fine-tuned модели\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "print(\"Loading model...\")\n",
    "config = PeftConfig.from_pretrained(MODEL_DIR)\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(base_model, MODEL_DIR)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Генерация\n",
    "def predict(description, max_length=OUTPUT_SEQ_LENGTH):\n",
    "    prompt = PROMPT.format(description=description)\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=INPUT_SEQ_LENGTH\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=max_length,\n",
    "            num_beams=NUM_BEAMS, # попробовать меньше\n",
    "            #temperature=TEMPERATURE, # параметризовать\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    #print(output_text)\n",
    "    #print(pseudo_text_to_json(output_text))\n",
    "    try:\n",
    "        parsed_json = pseudo_text_to_json(output_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка парсинга JSON: {e}\")\n",
    "        print(\"Сырые данные:\", output_text)\n",
    "        parsed_json = None\n",
    "\n",
    "    return parsed_json\n",
    "\n",
    "\n",
    "text = input(\"Введите описание сцены: \")\n",
    "result = predict(text)\n",
    "print(\"\\nПредсказание:\\n\")\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c10247e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c10247e",
    "outputId": "3a52a558-bf44-4cef-8b2b-48d06c39e3b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'кот': ['черный']},\n",
       " {'кот': ['черный']},\n",
       " {'кот': ['черный']},\n",
       " {'дерево': ['красное']},\n",
       " {'дерево': []}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_text_to_json(\"кот (черный) кот (черный) кот (черный) дерево (красное) дерево ()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BNI6xvqjLGa1",
   "metadata": {
    "id": "BNI6xvqjLGa1"
   },
   "source": [
    "## Просмотр сколько параметров учили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12106970",
   "metadata": {
    "id": "12106970"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    total_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "\n",
    "    print(f\"Всего параметров: {total_params / 1e6:.2f}M\")\n",
    "    print(f\"Обучаемых параметров: {trainable_params / 1e6:.2f}M\")\n",
    "    print(f\"Доля обучаемых параметров: {100 * trainable_params / total_params:.2f}%\")\n",
    "\n",
    "# Вызов функции после создания модели\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ac12b",
   "metadata": {
    "id": "3c1ac12b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019569ec3bdd424b9fc3dfca37f8fe0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066e038f8a0c48ce912bed6526ed7540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ffaca97765c42d6b335a53bbc2be714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f7045a08106433fb61bd4eb71f93c3f",
      "placeholder": "​",
      "style": "IPY_MODEL_af0bf2b4858a436381f483e50ce9bf02",
      "value": " 16/16 [00:00&lt;00:00, 342.26 examples/s]"
     }
    },
    "2450d93c7a9042a4830a2888dda875fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6b7acf12727418d827a6cdf6b00a57b",
      "max": 286,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46dc82e68a674b129aafc99cf4927b9e",
      "value": 286
     }
    },
    "26186dbcbcc34a2c92b0137624b73403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5614c6d61cf4441bbd21bfcd00d1b5ea",
      "placeholder": "​",
      "style": "IPY_MODEL_f6115fc3752840c6b4145093a5c748e9",
      "value": "Map: 100%"
     }
    },
    "279311b7b53c42e8b82bc1b2a8e3dee6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315d315ab75a425d8d6cd9d6bac96189": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e32e17c33da4d9794aabd1c1717c027": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f7045a08106433fb61bd4eb71f93c3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46dc82e68a674b129aafc99cf4927b9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5614c6d61cf4441bbd21bfcd00d1b5ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58877fa41490498d933e3b44e19c45f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f861d864aec5454b937bea74368fa287",
       "IPY_MODEL_2450d93c7a9042a4830a2888dda875fc",
       "IPY_MODEL_86a38d91c7884fec9307ddc12c5d2570"
      ],
      "layout": "IPY_MODEL_279311b7b53c42e8b82bc1b2a8e3dee6"
     }
    },
    "7aa2c1bd8edf404ead0faad35b35159f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b9e83c55ad246729c5be747c73ae262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e6c938a54e34543a7fd9fba27297118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26186dbcbcc34a2c92b0137624b73403",
       "IPY_MODEL_d677a730bb704b718f11cbb5e2314622",
       "IPY_MODEL_0ffaca97765c42d6b335a53bbc2be714"
      ],
      "layout": "IPY_MODEL_7aa2c1bd8edf404ead0faad35b35159f"
     }
    },
    "86a38d91c7884fec9307ddc12c5d2570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_315d315ab75a425d8d6cd9d6bac96189",
      "placeholder": "​",
      "style": "IPY_MODEL_066e038f8a0c48ce912bed6526ed7540",
      "value": " 286/286 [00:00&lt;00:00, 625.43 examples/s]"
     }
    },
    "a6272f05ce8e4d6b8ebfa2282d4cd422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af0bf2b4858a436381f483e50ce9bf02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d677a730bb704b718f11cbb5e2314622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_019569ec3bdd424b9fc3dfca37f8fe0d",
      "max": 16,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6272f05ce8e4d6b8ebfa2282d4cd422",
      "value": 16
     }
    },
    "f6115fc3752840c6b4145093a5c748e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6b7acf12727418d827a6cdf6b00a57b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f861d864aec5454b937bea74368fa287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e32e17c33da4d9794aabd1c1717c027",
      "placeholder": "​",
      "style": "IPY_MODEL_7b9e83c55ad246729c5be747c73ae262",
      "value": "Map: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
