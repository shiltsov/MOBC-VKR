{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e34947",
   "metadata": {},
   "source": [
    "# T5rus с промптом + LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b149213",
   "metadata": {},
   "source": [
    "Будем напрямую генерировать json по сцене, для этого дообучим T5(Text-To-Text Transfer Transformer) + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os \n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftConfig,PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# отключаем их все чтобы картинку не портили\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "#DATA_DIR = Path(\"../dataset/dataset_syntetic_v4\").expanduser()\n",
    "DATA_DIR = Path(\"../dataset/dataset_tmp\").expanduser()\n",
    "MODEL_NAME = \"sberbank-ai/ruT5-base\"\n",
    "\n",
    "lib_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "from library.metrics import evaluate_scene_extraction, evaluate_global_f1_on_pairs\n",
    "from library.safe_compute_metrics import safe_compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "import torch\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)\n",
    "print(huggingface_hub.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccb28b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Описание сцены: {description}\n",
    "Инструкция: выдели все объекты и их признаки.\n",
    "Формат ответа: только JSON следующего вида:\n",
    "{{\"объекты\": {{\"название объекта\": [\"атрибут1\", \"атрибут2\", ...], ...}}}}\n",
    "\n",
    "Важно:\n",
    "- Не добавляй текст, пояснения или комментарии\n",
    "- Не пропускай объекты без признаков (если есть)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac571cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvaluateCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Кастомный колбэк для логирования и визуализации метрик после каждой эпохи.\n",
    "    НЕ пересчитывает предсказания, а берет метрики прямо из Trainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, save_path=\"./metrics/\"):\n",
    "        self.save_path = Path(save_path)\n",
    "        self.metrics_history = []\n",
    "\n",
    "        self.save_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Срабатывает после валидации в Trainer.\n",
    "        \"\"\"\n",
    "        if metrics is None:\n",
    "            return\n",
    "\n",
    "        metrics_to_log = {\n",
    "            \"epoch\": state.epoch,\n",
    "            \"f1_object\": metrics.get(\"f1_object\", 0.0),\n",
    "            \"f1_attribute\": metrics.get(\"f1_attribute\", 0.0),\n",
    "            \"f1_combined_weighted\": metrics.get(\"f1_combined_weighted\", 0.0),\n",
    "            \"f1_combined_simple\": metrics.get(\"f1_combined_simple\", 0.0),\n",
    "            \"valid_json_rate\": metrics.get(\"valid_json_rate\", 0.0),\n",
    "        }\n",
    "\n",
    "        self.metrics_history.append(metrics_to_log)\n",
    "\n",
    "        # Логируем в консоль\n",
    "        print(f\"\\n Custom evaluation at epoch {state.epoch:.2f}: {metrics_to_log}\")\n",
    "\n",
    "        # Сохраняем историю метрик\n",
    "        with open(self.save_path / \"metrics_history.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        # Строим графики\n",
    "        self.plot_metrics()\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        if not self.metrics_history:\n",
    "            return\n",
    "\n",
    "        epochs = [m[\"epoch\"] for m in self.metrics_history]\n",
    "        plt.figure(figsize=(12, 7))\n",
    "\n",
    "        for key in [\"f1_object\", \"f1_attribute\", \"f1_combined_weighted\", \"f1_combined_simple\", \"valid_json_rate\"]:\n",
    "            plt.plot(epochs, [m[key] for m in self.metrics_history], label=key)\n",
    "\n",
    "        plt.xlabel(\"Эпоха\")\n",
    "        plt.ylabel(\"Метрика\")\n",
    "        plt.title(\"Кривые метрик по эпохам\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(self.save_path / \"learning_curves.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def safe_parse_json(text):\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Если predictions — logits, нужно брать argmax\n",
    "\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "    # logits -> ids\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    print(\"preds:\", decoded_preds)    \n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    f1_object_list = []\n",
    "    f1_attribute_list = []\n",
    "    f1_combined_weighted_list = []\n",
    "    f1_combined_simple_list = []\n",
    "    valid = 0\n",
    "\n",
    "    for pred_text, label_text in zip(decoded_preds, decoded_labels):\n",
    "        pred_json = safe_parse_json(pred_text)\n",
    "        label_json = safe_parse_json(label_text)\n",
    "\n",
    "        if pred_json is None or label_json is None:\n",
    "            # Невалидный JSON → 0 по всем метрикам\n",
    "            f1_object_list.append(0.0)\n",
    "            f1_attribute_list.append(0.0)\n",
    "            f1_combined_weighted_list.append(0.0)\n",
    "            f1_combined_simple_list.append(0.0)\n",
    "        else:\n",
    "            valid += 1\n",
    "            scores = evaluate_scene_extraction(label_json, pred_json)\n",
    "            f1_object_list.append(scores[\"f1_object\"])\n",
    "            f1_attribute_list.append(scores[\"f1_attribute\"])\n",
    "            f1_combined_weighted_list.append(scores[\"f1_combined_weighted\"])\n",
    "            f1_combined_simple_list.append(scores[\"f1_combined_simple\"])\n",
    "\n",
    "    total = len(decoded_preds)\n",
    "\n",
    "    return {\n",
    "        \"f1_object\": round(sum(f1_object_list) / total, 4),\n",
    "        \"f1_attribute\": round(sum(f1_attribute_list) / total, 4),\n",
    "        \"f1_combined_weighted\": round(sum(f1_combined_weighted_list) / total, 4),\n",
    "        \"f1_combined_simple\": round(sum(f1_combined_simple_list) / total, 4),\n",
    "        \"valid_json_rate\": round(valid / total, 4),\n",
    "        \"total_samples\": total,\n",
    "        \"valid_samples\": valid,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b895227",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# === 1. Load all JSONL batches ===\n",
    "def make_target(scene_objects):\n",
    "    objects_dict = {}\n",
    "    for obj in scene_objects:\n",
    "        for name, attrs in obj.items():\n",
    "            objects_dict[name] = attrs\n",
    "    return json.dumps({\"объекты\": objects_dict}, ensure_ascii=False)\n",
    "\n",
    "data = []\n",
    "for path in sorted(DATA_DIR.glob(\"*.jsonl\")):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            description = item[\"description\"]\n",
    "            target = make_target(item[\"scene\"][\"objects\"]) \n",
    "            data.append({\n",
    "                \"input\": PROMPT.format(description=description),\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "# === 2. Convert to HuggingFace Dataset ===\n",
    "dataset = Dataset.from_list(data)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "train_ds, val_ds = dataset[\"train\"], dataset[\"test\"]\n",
    "\n",
    "# === 3. Tokenizer ===\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(example):\n",
    "    inputs = tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    targets = tokenizer(example[\"target\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=False)\n",
    "val_ds = val_ds.map(preprocess, batched=False)\n",
    "\n",
    "print(dataset[\"train\"][0][\"input\"])\n",
    "print(dataset[\"train\"][0][\"target\"])\n",
    "\n",
    "# === 4. Load base model and apply LoRA ===\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8, # ранг низкоранговой матрицы\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q\", \"v\"],  # ruT5 может требовать уточнения слоёв (или просто \"SelfAttention\")\n",
    "    # target_modules=[\"q\", \"k\", \"v\", \"o\"]\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# === 5. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rut5_lora_outputs\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=1, # для маленькой памяти GPU   \n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True  # если у тебя есть GPU с поддержкой\n",
    ")\n",
    "\n",
    "# === 6. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  # <-- исправленная функция\n",
    "    callbacks=[\n",
    "        CustomEvaluateCallback(\n",
    "            save_path=\"./metrics/\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# === 7. Train ===\n",
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./rut5_lora_outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53de621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1970de3a",
   "metadata": {},
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./rut5_lora_outputs\"  # путь к fine-tuned модели\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === 1. Загрузка модели и токенизатора ===\n",
    "print(\"Loading model...\")\n",
    "config = PeftConfig.from_pretrained(MODEL_DIR)\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(base_model, MODEL_DIR)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# === 2. Генерация ===\n",
    "def predict(description: str, max_length: int = 256):\n",
    "    prompt = PROMPT.format(description=description)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        parsed_json = json.loads(output_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка парсинга JSON: {e}\")\n",
    "        print(\"Сырые данные:\", output_text)\n",
    "        parsed_json = None\n",
    "\n",
    "    return parsed_json\n",
    "\n",
    "\n",
    "# === 3. Пример использования ===\n",
    "if __name__ == \"__main__\":\n",
    "    text = input(\"Введите описание сцены: \")\n",
    "    result = predict(text)\n",
    "    print(\"\\nПредсказание:\\n\")\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10247e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12106970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    total_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "\n",
    "    print(f\"Всего параметров: {total_params / 1e6:.2f}M\")\n",
    "    print(f\"Обучаемых параметров: {trainable_params / 1e6:.2f}M\")\n",
    "    print(f\"Доля обучаемых параметров: {100 * trainable_params / total_params:.2f}%\")\n",
    "\n",
    "# Вызов функции после создания модели\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ac12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
