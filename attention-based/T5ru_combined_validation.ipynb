{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd180b4",
   "metadata": {},
   "source": [
    "## Построение сценического графа по текстовому описанию сцены\n",
    "\n",
    "### Итоговая валидация модели\n",
    "\n",
    "архитектура модели:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4255069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftConfig,PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# отключаем их все чтобы картинку не портили\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "DATA_DIR = Path(\"../dataset/dataset_validation_spacial\").expanduser()\n",
    "MODEL_NAME = \"sberbank-ai/ruT5-base\"\n",
    "\n",
    "lib_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "from library.final_metrics import evaluate_obj_attr_metrics, evaluate_ged_score\n",
    "from library.utils import json_to_pseudo_text, pseudo_text_to_json\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Путь к папке с датасетом\n",
    "DATASET_DIR = \"../dataset/dataset_validation_spacial\"\n",
    "VAL_SPLIT = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "716a55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c596db6",
   "metadata": {},
   "source": [
    "### Параметры для модели, определяющей объекты и признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb4d8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR_OBJ = \"../models/T5ru_PsC_lora_outputs\"  \n",
    "\n",
    "INPUT_SEQ_LENGTH_OBJ = 1100\n",
    "OUTPUT_SEQ_LENGTH_OBJ = 512\n",
    "\n",
    "NUM_BEAMS_OBJ = 8\n",
    "\n",
    "PROMPT_OBJ = \"\"\"\n",
    "Ты должен проанализировать описание сцены и вернуть ответ в специальном псевдоформате.\n",
    "\n",
    "Твоя задача:\n",
    "- Найди все объекты, упомянутые в описании, и их признаки.\n",
    "- Верни результат строго в псевдоформате — одной строкой.\n",
    "\n",
    "Формат:\n",
    "объект1 (признак1 признак2) объект2 () объект3 (признак)\n",
    "\n",
    "Требования:\n",
    "- Каждый объект указывается один раз.\n",
    "- Признаки пишутся через пробел внутри круглых скобок.\n",
    "- Если признаки отсутствуют, используй пустые скобки ().\n",
    "- Не добавляй объектов или признаков, которых нет в описании.\n",
    "- В ответе не должно быть никаких пояснений, комментариев или заголовков — только одна строка с результатом.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "Описание: Маленький красный стол стоит у окна.\n",
    "Ответ:\n",
    "стол (маленький красный) окно ()\n",
    "\n",
    "Описание: {description}\n",
    "\n",
    "Ответ:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442bacd",
   "metadata": {},
   "source": [
    "### Выделение объектов и признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8867c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objects_attrs(description):\n",
    "    \"\"\"\n",
    "    по текстовому описанию генерирует список объектов и атрибутов для сцены\n",
    "    \"\"\"\n",
    "\n",
    "    # Загрузка модели и токенизатора\n",
    "    config = PeftConfig.from_pretrained(MODEL_DIR_OBJ)\n",
    "    base_model = T5ForConditionalGeneration.from_pretrained(config.base_model_name_or_path)\n",
    "    model = PeftModel.from_pretrained(base_model, MODEL_DIR_OBJ)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    #print(model)\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "    \n",
    "    prompt = PROMPT_OBJ.format(description=description)\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=INPUT_SEQ_LENGTH_OBJ\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=OUTPUT_SEQ_LENGTH_OBJ,\n",
    "            num_beams=NUM_BEAMS_OBJ, # попробовать меньше\n",
    "            #temperature=TEMPERATURE, # параметризовать\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    try:\n",
    "        parsed_json = pseudo_text_to_json(output_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка парсинга JSON: {e}\")\n",
    "        print(\"Сырые данные:\", output_text)\n",
    "        parsed_json = None\n",
    "\n",
    "    return parsed_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e1dabe23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'учебник': ['жёлтый']}, {'лампа': ['синяя']}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"На столе стояла синяя лампа а рядом с ней жёлтый учебник\"\n",
    "make_objects_attrs(description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826c581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d750ef",
   "metadata": {},
   "source": [
    "### Параметры для модели, выделяющей пространственные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e59359c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR_SP = \"../models/T5ru_spacial_lora_outputs\" \n",
    "\n",
    "MAX_INPUT_LENGTH_SP = 512 \n",
    "MAX_OUTPUT_LENGTH_SP = 32 \n",
    "\n",
    "NUM_BEAMS_SP = 8\n",
    "\n",
    "PROMPT_SP = \"\"\"\n",
    "Определи пространственную связь между объектами '{obj1}' и '{obj2}'\n",
    "в следующем описании сцены: {description}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725aba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bfe6b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spatial_relations(description, obj1, obj2):\n",
    "    \"\"\"\n",
    "    по заданному текстовому описанию \n",
    "    \"\"\"\n",
    "    # Загрузка модели и токенизатора\n",
    "    config = PeftConfig.from_pretrained(MODEL_DIR_SP)\n",
    "    base_model = T5ForConditionalGeneration.from_pretrained(config.base_model_name_or_path)\n",
    "    model = PeftModel.from_pretrained(base_model, MODEL_DIR_SP)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    #print(model)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "    \n",
    "    prompt = PROMPT_SP.format(obj1=obj1, obj2=obj2, description=description)\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_INPUT_LENGTH_SP\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=MAX_OUTPUT_LENGTH_SP,\n",
    "            num_beams=NUM_BEAMS_SP,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "309c59db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'нет связи'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"кот рядом с полкой\"\n",
    "make_spatial_relations(description, \"полка\", \"кот\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e1b98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spatial_triplets(description, objects_with_attrs):\n",
    "    object_names = [list(obj.keys())[0] for obj in objects_with_attrs]  # ['учебник', 'лампа']\n",
    "    \n",
    "    triplets = []\n",
    "\n",
    "    for i in range(len(object_names)):\n",
    "        for j in range(len(object_names)):\n",
    "            if i == j:\n",
    "                continue  # пропустить пары с одинаковыми объектами\n",
    "            obj1 = object_names[i]\n",
    "            obj2 = object_names[j]\n",
    "            relation = make_spatial_relations(description, obj1, obj2)\n",
    "            if relation != \"нет связи\":\n",
    "                triplets.append([obj1, relation, obj2])\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a06183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['лампа', 'слева от', 'учебник']]\n"
     ]
    }
   ],
   "source": [
    "description = \"На столе лежит жёлтый учебник. Слева от него стоит синяя лампа.\"\n",
    "\n",
    "triplets = extract_spatial_triplets(description, make_objects_attrs(description))\n",
    "print(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d108058",
   "metadata": {},
   "source": [
    "## Сборка финальной модели\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c169ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T5ru_model(description, location=\"неизвестно\"):\n",
    "    # Извлечение предсказаний\n",
    "    obj_attr = make_objects_attrs(description)\n",
    "    relations = extract_spatial_triplets(description, obj_attr)      \n",
    "    \n",
    "    scene = dict()\n",
    "    scene[\"location\"] = location\n",
    "    scene[\"objects\"] = obj_attr\n",
    "    scene[\"relations\"] = relations\n",
    "    \n",
    "    return {\"scene\": scene}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "99d969db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scene': {'location': 'неизвестно',\n",
       "  'objects': [{'учебник': ['жёлтый']}, {'лампа': ['синяя']}],\n",
       "  'relations': [['лампа', 'слева от', 'учебник']]}}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"На столе лежит жёлтый учебник. Слева от него стоит синяя лампа.\"\n",
    "T5ru_model(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f69a6",
   "metadata": {},
   "source": [
    "### Большой финальный тест на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b090555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем все jsonl-файлы из датасета\n",
    "def load_dataset(path: str) -> List[Dict]:\n",
    "    dataset = []\n",
    "    for filename in glob.glob(os.path.join(path, \"*.jsonl\")):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                dataset.append(json.loads(line))\n",
    "    return dataset\n",
    "\n",
    "# Получаем .05 данных\n",
    "def sample_validation_split(dataset: List[Dict], fraction: float = 0.05) -> List[Dict]:\n",
    "    sample_size = max(1, int(len(dataset) * fraction))\n",
    "    return random.sample(dataset, sample_size)\n",
    "\n",
    "# Обработка + сбор метрик\n",
    "def evaluate_on_validation_set(dataset: List[Dict]) -> Dict[str, float]:\n",
    "    metrics_accumulator = defaultdict(list)\n",
    "    \n",
    "    for item in tqdm(dataset, ncols=80):\n",
    "        src_text = item[\"description\"]        \n",
    "        if not src_text:\n",
    "            print(\"Пустое или отсутствующее поле 'description' в элементе:\")\n",
    "            print(item)\n",
    "            continue\n",
    "        \n",
    "        pred = T5ru_model(src_text)\n",
    "        label = {\"scene\": item[\"scene\"]}\n",
    "        \n",
    "        # Оценка для базовых метрик\n",
    "        metrics = evaluate_obj_attr_metrics(pred, label)\n",
    "        for k, v in metrics.items():\n",
    "            metrics_accumulator[k].append(v)\n",
    "\n",
    "        # Оценка с точки зрения графа целиком\n",
    "        metrics = evaluate_ged_score(pred, label)\n",
    "        for k, v in metrics.items():\n",
    "            metrics_accumulator[k].append(v)\n",
    "            \n",
    "            \n",
    "    # Усреднение по всем примерам\n",
    "    return {k: round(sum(vs) / len(vs), 4) for k, vs in metrics_accumulator.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b0378dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 250/250 [2:27:22<00:00, 35.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results on 250 samples:\n",
      "f1_objects: 0.9826\n",
      "f1_attributes_macro: 0.7367\n",
      "f1_attributes_weighted: 0.9296\n",
      "f1_global_obj_attr_pairs: 1.0\n",
      "f1_combined_simple: 0.8597\n",
      "f1_combined_weighted: 0.9593\n",
      "GED_score: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = load_dataset(DATASET_DIR)\n",
    "val_data = sample_validation_split(all_data, VAL_SPLIT)\n",
    "final_metrics = evaluate_on_validation_set(val_data)\n",
    "\n",
    "print(\"Validation results on\", len(all_data), \"samples:\")\n",
    "for k, v in final_metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfceefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
